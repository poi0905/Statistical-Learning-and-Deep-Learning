{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第一題 [Data Preprocessing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_table('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', header=None)\n",
    "x_test = pd.read_table('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39, State-gov, 77516, Bachelors, 13, Never-mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50, Self-emp-not-inc, 83311, Bachelors, 13, Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38, Private, 215646, HS-grad, 9, Divorced, Han...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53, Private, 234721, 11th, 7, Married-civ-spou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28, Private, 338409, Bachelors, 13, Married-ci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  39, State-gov, 77516, Bachelors, 13, Never-mar...\n",
       "1  50, Self-emp-not-inc, 83311, Bachelors, 13, Ma...\n",
       "2  38, Private, 215646, HS-grad, 9, Divorced, Han...\n",
       "3  53, Private, 234721, 11th, 7, Married-civ-spou...\n",
       "4  28, Private, 338409, Bachelors, 13, Married-ci..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>|1x3 Cross validator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25, Private, 226802, 11th, 7, Never-married, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38, Private, 89814, HS-grad, 9, Married-civ-sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28, Local-gov, 336951, Assoc-acdm, 12, Married...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44, Private, 160323, Some-college, 10, Married...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0                               |1x3 Cross validator\n",
       "1  25, Private, 226802, 11th, 7, Never-married, M...\n",
       "2  38, Private, 89814, HS-grad, 9, Married-civ-sp...\n",
       "3  28, Local-gov, 336951, Assoc-acdm, 12, Married...\n",
       "4  44, Private, 160323, Some-college, 10, Married..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['age', 'workclass', 'fnlwgt', 'education', 'educational-num', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'y']\n",
    "x_train[column_names] = x_train[0].str.split(', ', expand=True)\n",
    "x_test[column_names] = x_test[0].str.split(', ', expand=True)\n",
    "\n",
    "x_train = x_train.iloc[:,1:]\n",
    "x_test = x_test.iloc[1:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把問號變成NaN才能使用dropna\n",
    "x_train = x_train.replace('?', np.NaN)\n",
    "x_train = x_train.dropna(axis=0, how='any')\n",
    "\n",
    "x_test = x_test.replace('?', np.NaN)\n",
    "x_test = x_test.dropna(axis=0, how='any')\n",
    "\n",
    "# 調整順序\n",
    "x_train = x_train[['capital-loss', 'hours-per-week', 'capital-gain', 'educational-num', 'age', 'fnlwgt',\n",
    "                  'relationship', 'race', 'gender', 'occupation', 'education', 'native-country', 'workclass', 'marital-status', 'y']]\n",
    "\n",
    "x_test = x_test[['capital-loss', 'hours-per-week', 'capital-gain', 'educational-num', 'age', 'fnlwgt',\n",
    "                  'relationship', 'race', 'gender', 'occupation', 'education', 'native-country', 'workclass', 'marital-status', 'y']]\n",
    "\n",
    "y_train = x_train['y']\n",
    "y_test = x_test['y']\n",
    "\n",
    "# remove y label\n",
    "x_train = x_train.drop('y', axis=1)\n",
    "x_test = x_test.drop('y', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "      <th>education</th>\n",
       "      <th>native-country</th>\n",
       "      <th>workclass</th>\n",
       "      <th>marital-status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>2174</td>\n",
       "      <td>13</td>\n",
       "      <td>39</td>\n",
       "      <td>77516</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>United-States</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Never-married</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>83311</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>215646</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Private</td>\n",
       "      <td>Divorced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "      <td>234721</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>11th</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Private</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>338409</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>Private</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  capital-loss hours-per-week capital-gain educational-num age  fnlwgt  \\\n",
       "0            0             40         2174              13  39   77516   \n",
       "1            0             13            0              13  50   83311   \n",
       "2            0             40            0               9  38  215646   \n",
       "3            0             40            0               7  53  234721   \n",
       "4            0             40            0              13  28  338409   \n",
       "\n",
       "    relationship   race  gender         occupation  education native-country  \\\n",
       "0  Not-in-family  White    Male       Adm-clerical  Bachelors  United-States   \n",
       "1        Husband  White    Male    Exec-managerial  Bachelors  United-States   \n",
       "2  Not-in-family  White    Male  Handlers-cleaners    HS-grad  United-States   \n",
       "3        Husband  Black    Male  Handlers-cleaners       11th  United-States   \n",
       "4           Wife  Black  Female     Prof-specialty  Bachelors           Cuba   \n",
       "\n",
       "          workclass      marital-status  \n",
       "0         State-gov       Never-married  \n",
       "1  Self-emp-not-inc  Married-civ-spouse  \n",
       "2           Private            Divorced  \n",
       "3           Private  Married-civ-spouse  \n",
       "4           Private  Married-civ-spouse  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    <=50K\n",
       "1    <=50K\n",
       "2    <=50K\n",
       "3    <=50K\n",
       "4    <=50K\n",
       "Name: y, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將'>50K'與'<=50K'轉成1跟0\n",
    "for i in y_train.index:\n",
    "    if y_train[i] == '<=50K':\n",
    "        y_train[i] = 0\n",
    "    else:\n",
    "        y_train[i] = 1\n",
    "    \n",
    "for i in y_test.index:\n",
    "    if y_test[i] == '<=50K.':\n",
    "        y_test[i] = 0\n",
    "    else:\n",
    "        y_test[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把連續變數從object變為number\n",
    "num_col = ['capital-loss', 'hours-per-week', 'capital-gain', 'educational-num', 'age', 'fnlwgt']\n",
    "\n",
    "x_train[num_col] = x_train[num_col].apply(pd.to_numeric, errors='coerce')\n",
    "x_test[num_col] = x_test[num_col].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 再區隔numerical和categorical\n",
    "# numerical\n",
    "x_train_num = x_train.select_dtypes(include='number')\n",
    "x_test_num = x_test.select_dtypes(include='number')\n",
    "# categorical\n",
    "x_train_cat = x_train.select_dtypes(exclude='number')\n",
    "x_test_cat = x_test.select_dtypes(exclude='number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize numerical df \n",
    "\n",
    "#scale = StandardScaler()\n",
    "#x_train_num_normalized = pd.DataFrame(scale.fit_transform(x_train_num), columns=x_train_num.keys())\n",
    "# x_test_num_normalized = pd.DataFrame(scale.fit_transform(x_test_num), columns=x_test_num.keys())\n",
    "\n",
    "mu = x_train_num.mean()\n",
    "std = x_train_num.std(ddof=0)\n",
    "\n",
    "x_train_num_normalized = (x_train_num - mu) / std\n",
    "x_test_num_normalized = (x_test_num - mu) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_dum = pd.get_dummies(x_train_cat)\n",
    "x_test_dum = pd.get_dummies(x_test_cat)\n",
    "# 把特徵值出現不到10次刪掉(針對訓練資料)\n",
    "x_train_dum = x_train_dum[x_train_dum.columns[x_train_dum.sum()>=10]]\n",
    "\n",
    "# 測試資料就看訓練資料的columns name\n",
    "x_test_dum = x_test_dum[x_train_dum.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因為等等要merge，所以先統一一下index\n",
    "x_train_dum.reset_index(drop=True)\n",
    "x_test_dum.reset_index(drop=True)\n",
    "\n",
    "# merge numerical and categorical\n",
    "x_train = x_train_num_normalized.merge(x_train_dum, how='outer', left_index=True, right_index=True)\n",
    "x_test = x_test_num_normalized.merge(x_test_dum, how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>relationship_Husband</th>\n",
       "      <th>relationship_Not-in-family</th>\n",
       "      <th>relationship_Other-relative</th>\n",
       "      <th>relationship_Own-child</th>\n",
       "      <th>...</th>\n",
       "      <th>workclass_Self-emp-not-inc</th>\n",
       "      <th>workclass_State-gov</th>\n",
       "      <th>workclass_Without-pay</th>\n",
       "      <th>marital-status_Divorced</th>\n",
       "      <th>marital-status_Married-AF-spouse</th>\n",
       "      <th>marital-status_Married-civ-spouse</th>\n",
       "      <th>marital-status_Married-spouse-absent</th>\n",
       "      <th>marital-status_Never-married</th>\n",
       "      <th>marital-status_Separated</th>\n",
       "      <th>marital-status_Widowed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-1.224066</td>\n",
       "      <td>-1.023104</td>\n",
       "      <td>0.350286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0.757005</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.033340</td>\n",
       "      <td>-0.946320</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>0.736754</td>\n",
       "      <td>-0.794697</td>\n",
       "      <td>1.392858</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.890601</td>\n",
       "      <td>-0.047574</td>\n",
       "      <td>0.423474</td>\n",
       "      <td>-0.278945</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.912474</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-1.616231</td>\n",
       "      <td>-0.337883</td>\n",
       "      <td>0.084232</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   capital-loss  hours-per-week  capital-gain  educational-num       age  \\\n",
       "1     -0.218586       -0.077734     -0.147445        -1.224066 -1.023104   \n",
       "2     -0.218586        0.757005     -0.147445        -0.439738 -0.033340   \n",
       "3     -0.218586       -0.077734     -0.147445         0.736754 -0.794697   \n",
       "4     -0.218586       -0.077734      0.890601        -0.047574  0.423474   \n",
       "6     -0.218586       -0.912474     -0.147445        -1.616231 -0.337883   \n",
       "\n",
       "     fnlwgt  relationship_Husband  relationship_Not-in-family  \\\n",
       "1  0.350286                     0                           0   \n",
       "2 -0.946320                     1                           0   \n",
       "3  1.392858                     1                           0   \n",
       "4 -0.278945                     1                           0   \n",
       "6  0.084232                     0                           1   \n",
       "\n",
       "   relationship_Other-relative  relationship_Own-child  ...  \\\n",
       "1                            0                       1  ...   \n",
       "2                            0                       0  ...   \n",
       "3                            0                       0  ...   \n",
       "4                            0                       0  ...   \n",
       "6                            0                       0  ...   \n",
       "\n",
       "   workclass_Self-emp-not-inc  workclass_State-gov  workclass_Without-pay  \\\n",
       "1                           0                    0                      0   \n",
       "2                           0                    0                      0   \n",
       "3                           0                    0                      0   \n",
       "4                           0                    0                      0   \n",
       "6                           0                    0                      0   \n",
       "\n",
       "   marital-status_Divorced  marital-status_Married-AF-spouse  \\\n",
       "1                        0                                 0   \n",
       "2                        0                                 0   \n",
       "3                        0                                 0   \n",
       "4                        0                                 0   \n",
       "6                        0                                 0   \n",
       "\n",
       "   marital-status_Married-civ-spouse  marital-status_Married-spouse-absent  \\\n",
       "1                                  0                                     0   \n",
       "2                                  1                                     0   \n",
       "3                                  1                                     0   \n",
       "4                                  1                                     0   \n",
       "6                                  0                                     0   \n",
       "\n",
       "   marital-status_Never-married  marital-status_Separated  \\\n",
       "1                             1                         0   \n",
       "2                             0                         0   \n",
       "3                             0                         0   \n",
       "4                             0                         0   \n",
       "6                             1                         0   \n",
       "\n",
       "   marital-status_Widowed  \n",
       "1                       0  \n",
       "2                       0  \n",
       "3                       0  \n",
       "4                       0  \n",
       "6                       0  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_array = x_train.values\n",
    "x_test_array = x_test.values\n",
    "y_train_array = y_train.values\n",
    "y_test_array = y_test.values\n",
    "columnname = x_train.columns.values\n",
    "num_col = x_train_num.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult50k = {'x_train': x_train_array,\n",
    "           'y_train': y_train_array,\n",
    "           'x_test': x_test_array,\n",
    "           'y_test': y_test_array,\n",
    "           'columnname': columnname,\n",
    "           'num_col': num_col}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train 180972 elements no match!\n",
      "x_test 90360 elements no match!\n",
      "y_train match!\n",
      "y_test match!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "dsfile = 'adult_m50k.pickle'\n",
    "with open(dsfile, 'rb') as fh1:\n",
    "    adult50kp = pickle.load(fh1)\n",
    "    \n",
    "elems = ['x_train', 'x_test', 'y_train', 'y_test']\n",
    "\n",
    "for aelem in elems:\n",
    "    cnomatch = np.sum(adult50kp[aelem] != adult50k[aelem])\n",
    "    if cnomatch == 0:\n",
    "        print(aelem, \"match!\")\n",
    "    else:\n",
    "        print(aelem, \"%d elements no match!\" % cnomatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 檢查發現其實只是小數點後十位數以上有些微差異，故實作正確"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train match!\n",
      "x_test match!\n",
      "y_train match!\n",
      "y_test match!\n"
     ]
    }
   ],
   "source": [
    "for aelem in elems:\n",
    "    # 取到小數點後十位\n",
    "    cnomatch = np.sum(round(adult50kp[aelem].sum(), 10) != round(adult50k[aelem].sum(), 10))\n",
    "    if cnomatch == 0:\n",
    "        print(aelem, \"match!\")\n",
    "    else:\n",
    "        print(aelem, \"%d elements no match!\" % cnomatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第二題 [ROC and AUC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.848406\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from numpy import trapz\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "    \n",
    "#train prediction model    \n",
    "c = 0.3\n",
    "lr2 = LogisticRegression(solver = 'lbfgs', C= c, max_iter = 1000)\n",
    "lr2.fit(adult50kp['x_train'], adult50kp['y_train'])\n",
    "#make prediction\n",
    "ypred = lr2.predict(adult50kp['x_test'])\n",
    "ypredprob = lr2.predict_proba(adult50kp['x_test'])\n",
    "#compute accuracy\n",
    "ncorrect = np.sum(adult50kp['y_test'] == ypred)\n",
    "accuracy_sk = ncorrect / adult50kp['y_test'].shape[0]\n",
    "print(\"Accuracy = %f\" % accuracy_sk)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class roc_auc():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def confusion_matrix(self, ground_truth, predict_score, threshold=0.5):\n",
    "    \n",
    "        self.tp=self.fp=self.tn=self.fn=0\n",
    "        self.truth = ground_truth\n",
    "        self.score = predict_score\n",
    "        bool_actuals = [a==1 for a in ground_truth]  # True / False\n",
    "\n",
    "        for i in range(len(ground_truth)):\n",
    "            if predict_score[i] > threshold:\n",
    "                if bool_actuals[i] == True:\n",
    "                    self.tp += 1\n",
    "                else:\n",
    "                    self.fp += 1\n",
    "            else:\n",
    "                if bool_actuals[i] == False:\n",
    "                    self.tn += 1\n",
    "                else:\n",
    "                    self.fn += 1\n",
    "        \n",
    "        return self.tp, self.fp, self.tn, self.fn\n",
    "\n",
    "    def acc(self):\n",
    "   \n",
    "        return (self.tp+self.tn) / (self.tp+self.fp+self.tn+self.fn)\n",
    "\n",
    "    def fpr(self):\n",
    "    \n",
    "        return self.fp / (self.fp+self.tn) if (self.fp+self.tn)!=0 else 0\n",
    "\n",
    "    def tpr(self):\n",
    "        \n",
    "        return self.tp / (self.tp+self.fn) if (self.tp+self.fn)!=0 else 0\n",
    "    \n",
    "    def different_threshold(self):\n",
    "        \n",
    "        low = min(self.score)\n",
    "        high = max(self.score)\n",
    "        step = (abs(low) + abs(high)) / 1000  # 1000 steps\n",
    "        threshold = np.arange(low-step, high+step, step)\n",
    "        \n",
    "        fpr_list = []\n",
    "        tpr_list = []\n",
    "        \n",
    "        for t in threshold:\n",
    "            self.confusion_matrix(self.truth, self.score, t)\n",
    "            fpr_list.append(self.fpr())\n",
    "            tpr_list.append(self.tpr())\n",
    "            \n",
    "        self.fprlist = fpr_list\n",
    "        self.tprlist = tpr_list\n",
    "            \n",
    "        return fpr_list, tpr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ans = roc_auc()\n",
    "ans.confusion_matrix(adult50kp['y_test'], ypredprob[:,1])\n",
    "\n",
    "# check\n",
    "# print(ans.acc())\n",
    "# print(ans.different_threshold())\n",
    "\n",
    "fpr_list = ans.different_threshold()[0]\n",
    "tpr_list = ans.different_threshold()[1]\n",
    "auc = np.trapz(tpr_list[::-1],fpr_list[::-1])\n",
    "\n",
    "# Generate plot\n",
    "plt.title('AUC={}'.format(round(auc,3)))\n",
    "plt.plot(fpr_list, tpr_list, label = 'ROC curve')\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.legend()\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 成功繪製出 ROC curve 與計算出 AUC = 0.903"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第三題 [Logistic Regression with L2 Regularization]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://raw.githubusercontent.com/poi0905/blog/master/assets/img/posts/S__2261074.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$w^{(new)} = w^{(old)} - H^{-1} \\nabla E$\n",
    "\n",
    "$\\nabla E(w) = \\lambda w^{(old)} + \\phi^T (y-t)$\n",
    "\n",
    "$\\nabla \\nabla w^{(old)} = \\phi^T R \\phi + \\lambda I$\n",
    "\n",
    "$w^{(new)} = w^{(old)} - (\\phi^T R \\phi + \\lambda I)^{-1}[\\lambda w^{(old)} + \\phi^T (y-t)]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "dsfile = 'adult_m50k.pickle'\n",
    "with open(dsfile, 'rb') as fh1:\n",
    "    adult50kp = pickle.load(fh1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = adult50kp['x_train']\n",
    "x_test = adult50kp['x_test']\n",
    "y_train = adult50kp['y_train']\n",
    "y_test = adult50kp['y_test']\n",
    "columnname = adult50kp['columnname']\n",
    "num_col = adult50kp['num_col']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mylogistic_l2():\n",
    "    \n",
    "    def __init__(self, reg_vec, max_iter = 100, tol = 1e-5, add_intercept = True):\n",
    "        \"\"\"reg_vec: the regularization coefficient vector\n",
    "           max_iter: maximum number of iteration to run for the Newton method\n",
    "           tol: tolerance for the objective function\n",
    "           add_intercept: whether to add intercept (a column of ones) at last column of the feature matrix\"\"\"\n",
    "        \n",
    "        self.reg_vec = reg_vec\n",
    "        self.iter = max_iter\n",
    "        self.add = add_intercept\n",
    "        self.tol = tol\n",
    "        \n",
    "    def sigmoid(self, a):\n",
    "    \n",
    "        return 1 / (1+np.exp(-a))\n",
    "    \n",
    "    def newton_raphson(self, phi, weight, label, lamb):\n",
    "        \n",
    "        # phi: 30162x103\n",
    "        # weight: 103x1\n",
    "        # lamb: 103x103\n",
    "        # label: 30162x1\n",
    "        \n",
    "        y = phi @ weight  # 30162x1\n",
    "        prob = self.sigmoid(y)  # 30162x1\n",
    "        R = np.diag(prob * (1-prob))  # 30162x30162\n",
    "        gradient = phi.T @ (prob-label) + lamb @ weight  # 103x1\n",
    "        hessian = phi.T @ R @ phi + lamb @ np.eye(len(phi.T @ R @ phi))\n",
    "        error = -(label.T @ np.log(prob) + (1-label.T) @ np.log(1-prob)) + (weight.T @ lamb @ weight.T)/2  # scaler\n",
    "        weight = weight - np.linalg.inv(hessian) @ gradient\n",
    "        print(\"Error:\",error)\n",
    "        self.error = error\n",
    "        \n",
    "        return weight\n",
    "    \n",
    "    def fit(self, x, y, verbal = False):\n",
    "        \n",
    "        self.x = x_train\n",
    "        self.y = y_train\n",
    "        step = 0\n",
    "        \n",
    "        if self.add is True:\n",
    "            x_with_intercept = np.c_[x_train, np.ones((self.x.shape[0],1))]\n",
    "            self.weight = np.zeros(x_with_intercept.shape[1])  # initial weight\n",
    "            errorlist = [100000]\n",
    "            \n",
    "            while step < self.iter:\n",
    "                print(\"Iteration:\", step+1, end=\"; \")\n",
    "                step += 1\n",
    "                self.weight = self.newton_raphson(x_with_intercept, self.weight, y_train, self.reg_vec)\n",
    "                errorlist.append(self.error)\n",
    "                if errorlist[-2] - self.error >= self.tol:\n",
    "                    continue\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "        else:\n",
    "            self.weight = np.zeros(x_train.shape[1])\n",
    "            errorlist = [100000]\n",
    "            \n",
    "            while step < self.iter:\n",
    "                print(\"Iteration:\", step+1, end=\"; \")\n",
    "                step += 1\n",
    "                self.weight = self.newton_raphson(x_train, self.weight, y_train, self.reg_vec)\n",
    "                errorlist.append(self.error)\n",
    "                if errorlist[-2] - self.error >= self.tol:\n",
    "                    continue\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "    def predict(self, x):\n",
    "        \n",
    "        self.x = x_test\n",
    "        \n",
    "        if self.add is True:\n",
    "            x_test_with_intercept = np.c_[x_test, np.ones((self.x.shape[0],1))]\n",
    "            prob = self.sigmoid(x_test_with_intercept @ self.weight)\n",
    "        else:\n",
    "            prob = self.sigmoid(x_test @ self.weight)\n",
    "        \n",
    "        pred = []\n",
    "        \n",
    "        for p in prob:\n",
    "            if p >= 0.5:\n",
    "                pred.append(1)\n",
    "            else:\n",
    "                pred.append(0)\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 1: lambda = 1 for all coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1; Error: 20906.705260049082\n",
      "Iteration: 2; Error: 11873.289252229037\n",
      "Iteration: 3; Error: 10409.613016183863\n",
      "Iteration: 4; Error: 9873.584241076634\n",
      "Iteration: 5; Error: 9780.550633774263\n",
      "Iteration: 6; Error: 9775.287544510524\n",
      "Iteration: 7; Error: 9775.247129672623\n",
      "Iteration: 8; Error: 9775.247122461373\n",
      "Weight:\n",
      " [ 2.58310749e-01  3.52951378e-01  2.33390153e+00  7.51145211e-01\n",
      "  3.33524430e-01  7.92368681e-02 -2.59305996e-01 -3.31058935e-02\n",
      " -8.02092305e-01 -1.16328381e+00 -1.57480242e-01  1.06974336e+00\n",
      " -6.33846060e-01  1.16732407e-01 -2.31567383e-01 -5.17122209e-01\n",
      " -7.97216481e-02 -1.09949780e+00 -2.46027090e-01  6.19694925e-02\n",
      "  1.26685883e-01  8.62656059e-01 -9.18352843e-01 -6.21226177e-01\n",
      " -2.00740224e-01 -7.51600981e-01 -1.61011588e+00  5.75820911e-01\n",
      "  6.48995282e-01  3.53741433e-01  7.17218474e-01 -2.84494746e-02\n",
      " -9.54820902e-04 -1.96540899e-01 -1.46351641e-01  6.26946274e-01\n",
      "  4.48207080e-01  2.45945817e-02  4.69223656e-02 -4.91067747e-01\n",
      " -2.03035424e-01 -1.63303681e-01 -1.76623509e-02 -1.11328323e-01\n",
      " -9.94618248e-02 -1.17391916e+00  1.80702677e-01 -6.92720011e-02\n",
      "  9.76496905e-01  4.60988601e-01 -4.95440415e-01 -1.27203531e+00\n",
      "  4.86772406e-01 -8.98963733e-01 -6.00542600e-02 -3.50848853e-01\n",
      "  4.32815220e-01  5.94120149e-01  5.82151924e-01 -6.20962284e-01\n",
      " -5.97480379e-02  9.29035249e-02 -1.51892101e-01 -5.38528876e-03\n",
      "  3.41609085e-02 -2.89088237e-01  1.56053911e-01  4.95401242e-01\n",
      "  8.90942264e-01  1.49151436e-01  3.42484780e-01 -3.13312160e-01\n",
      " -3.55939108e-01 -3.62494608e-01 -6.67247475e-01 -4.08831131e-01\n",
      "  4.47489831e-01  1.37768930e-01  1.41351233e-01 -1.16015422e-01\n",
      " -5.61032710e-02 -9.34583043e-01 -2.92596528e-02 -2.99012958e-01\n",
      " -1.50511251e-01  3.52331870e-01 -7.85846535e-01  5.80200206e-01\n",
      "  4.97042310e-01 -1.90320741e-01 -3.47718541e-04  1.74993803e-01\n",
      " -4.88202696e-01 -3.12259617e-01 -1.02643023e+00 -7.22310843e-01\n",
      "  1.44672470e+00  1.15520747e+00 -6.80202911e-01 -1.21195631e+00\n",
      " -7.98338514e-01 -5.34648493e-01 -1.34552489e+00]\n",
      "Accuracy 0.847875166002656\n"
     ]
    }
   ],
   "source": [
    "lambda_vec = np.eye(len(x_train[0])+1)\n",
    "\n",
    "logic1 = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic1.fit(x_train, y_train)\n",
    "ypred = logic1.predict(x_test)\n",
    "acc = list(ypred != y_test).count(False) / len(ypred)\n",
    "print(\"Weight:\\n\", logic1.weight)\n",
    "print(\"Accuracy\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 2: lambda = 1 for all but the intercept, no regularization for intercept term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1; Error: 20906.705260049082\n",
      "Iteration: 2; Error: 11873.705635083028\n",
      "Iteration: 3; Error: 10410.536427777906\n",
      "Iteration: 4; Error: 9874.917035624685\n",
      "Iteration: 5; Error: 9782.087595784345\n",
      "Iteration: 6; Error: 9776.85804183674\n",
      "Iteration: 7; Error: 9776.818412455705\n",
      "Iteration: 8; Error: 9776.818405578848\n",
      "Weight:\n",
      " [ 0.25829765  0.35286355  2.33421989  0.76093037  0.33328473  0.07921358\n",
      " -0.41906501 -0.20451829 -0.96293739 -1.33000528 -0.32887968  0.90975624\n",
      " -0.82700343 -0.08741964 -0.4336111  -0.70534448 -0.28227076 -1.59439589\n",
      " -0.74125352 -0.01306693  0.05205653  0.78777243 -0.99240259 -0.69494818\n",
      " -0.27531241 -0.82656048 -1.65298179  0.50035667  0.5744047   0.27914971\n",
      "  0.64286175 -0.10294563 -0.05522086 -0.25465123 -0.20782379  0.59348693\n",
      "  0.40713026 -0.02200255 -0.00265095 -0.56924112 -0.27740542 -0.24561796\n",
      " -0.10973204 -0.1785307  -0.18530458 -1.1801582   0.09228902 -0.14021619\n",
      "  0.95308764  0.43076916 -0.52328048 -1.29561268  0.45661075 -0.92159731\n",
      " -0.08387461 -0.377851    0.40295961  0.56788744  0.5513525  -0.646118\n",
      " -0.08193625  0.06989464 -0.15796955 -0.02724891  0.01354307 -0.31896669\n",
      "  0.12772484  0.4727378   0.8610213   0.12126426  0.31527274 -0.33233611\n",
      " -0.38869331 -0.38430904 -0.67919585 -0.42890424  0.417121    0.10920407\n",
      "  0.11723865 -0.14731267 -0.07426403 -0.96113575 -0.05557072 -0.31865535\n",
      " -0.16974509  0.31952357 -0.80987719  0.55779359  0.34408602 -0.34313169\n",
      " -0.15401317  0.02252656 -0.64130567 -0.46470984 -1.09910162 -0.8664389\n",
      "  1.32356592  0.99914099 -0.81846028 -1.35692458 -0.94010276 -0.67642979]\n",
      "Accuracy 0.847808764940239\n"
     ]
    }
   ],
   "source": [
    "lambda_vec = np.eye(len(x_train[0]))\n",
    "\n",
    "logic1 = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = False)\n",
    "logic1.fit(x_train, y_train)\n",
    "ypred = logic1.predict(x_test)\n",
    "acc = list(ypred != y_test).count(False) / len(ypred)\n",
    "print(\"Weight:\\n\", logic1.weight)\n",
    "print(\"Accuracy\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 3: lambda = 1 for numerical-valued features, lambda = 0.5 for binary-valued features, no regularization for intercept term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1; Error: 20906.705260049082\n",
      "Iteration: 2; Error: 11871.151748396887\n",
      "Iteration: 3; Error: 10405.277281416737\n",
      "Iteration: 4; Error: 9866.967299325604\n",
      "Iteration: 5; Error: 9772.044289226305\n",
      "Iteration: 6; Error: 9766.37669282431\n",
      "Iteration: 7; Error: 9766.328165837205\n",
      "Iteration: 8; Error: 9766.328155516712\n",
      "Iteration: 9; Error: 9766.3281555167\n",
      "Weight:\n",
      " [ 0.25849111  0.35322394  2.33598766  0.80720414  0.33410071  0.07936585\n",
      " -0.49370728 -0.19295337 -1.0050973  -1.34229158 -0.31468835  0.84363046\n",
      " -0.87808667 -0.09614551 -0.46490749 -0.75188895 -0.31407879 -1.68121687\n",
      " -0.82389055  0.05603865  0.12039192  0.85796829 -0.93135847 -0.63212227\n",
      " -0.20669766 -0.76283362 -2.11758619  0.57041488  0.64714161  0.34852797\n",
      "  0.71540949 -0.03458635  0.04509671 -0.17291196 -0.14684918  0.80728452\n",
      "  0.57899054  0.11482209  0.11852947 -0.58010858 -0.267173   -0.27145853\n",
      " -0.18790836 -0.13079654 -0.22878516 -2.10646627  0.03377443 -0.11114761\n",
      "  1.12582835  0.47939214 -0.54372999 -1.51873069  0.51104375 -1.12042128\n",
      " -0.07188977 -0.38391316  0.45411871  0.6645264   0.6026661  -0.70054806\n",
      " -0.06921079  0.11223596 -0.25809655 -0.0218094   0.0438973  -0.31740654\n",
      "  0.16912286  0.58133396  0.93472721  0.16432701  0.35544573 -0.40736799\n",
      " -0.36621646 -0.43956779 -0.99743707 -0.50568081  0.44178914  0.15102727\n",
      "  0.16341912 -0.12281147 -0.07119001 -1.0257096  -0.04941245 -0.38276283\n",
      " -0.19463369  0.35428065 -0.90694455  0.69084484  0.3842178  -0.30548917\n",
      " -0.11471579  0.06167814 -0.60282267 -0.42775412 -1.5002216  -0.93320019\n",
      "  1.49153387  1.01871184 -0.90056393 -1.42141828 -1.01380578 -0.74636493]\n",
      "Accuracy 0.847675962815405\n"
     ]
    }
   ],
   "source": [
    "lambda_vec = np.eye(len(x_train[0]))\n",
    "lambda_vec /= 2\n",
    "\n",
    "# 前六項是numerical\n",
    "for i in range(6):\n",
    "    lambda_vec[i][i] = 1\n",
    "\n",
    "logic1 = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = False)\n",
    "logic1.fit(x_train, y_train)\n",
    "ypred = logic1.predict(x_test)\n",
    "acc = list(ypred != y_test).count(False) / len(ypred)\n",
    "print(\"Weight:\\n\", logic1.weight)\n",
    "print(\"Accuracy\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without print\n",
    "class Mylogistic_l2():\n",
    "    \n",
    "    def __init__(self, reg_vec, max_iter = 100, tol = 1e-5, add_intercept = True):\n",
    "        \"\"\"reg_vec: the regularization coefficient vector\n",
    "           max_iter: maximum number of iteration to run for the Newton method\n",
    "           tol: tolerance for the objective function\n",
    "           add_intercept: whether to add intercept (a column of ones) at last column of the feature matrix\"\"\"\n",
    "        \n",
    "        self.reg_vec = reg_vec\n",
    "        self.iter = max_iter\n",
    "        self.add = add_intercept\n",
    "        self.tol = tol\n",
    "        \n",
    "    def sigmoid(self, a):\n",
    "    \n",
    "        return 1 / (1+np.exp(-a))\n",
    "    \n",
    "    def newton_raphson(self, phi, weight, label, lamb):\n",
    "        \n",
    "        # phi: 30162x103\n",
    "        # weight: 103x1\n",
    "        # lamb: 103x103\n",
    "        # label: 30162x1\n",
    "        \n",
    "        y = phi @ weight  # 30162x1\n",
    "        prob = self.sigmoid(y)  # 30162x1\n",
    "        R = np.diag(prob * (1-prob))  # 30162x30162\n",
    "        gradient = phi.T @ (prob-label) + lamb @ weight  # 103x1\n",
    "        hessian = phi.T @ R @ phi + lamb @ np.eye(len(phi.T @ R @ phi))\n",
    "        error = -(label.T @ np.log(prob) + (1-label.T) @ np.log(1-prob)) + (weight.T @ lamb @ weight.T)/2  # scaler\n",
    "        weight = weight - np.linalg.inv(hessian) @ gradient\n",
    "#         print(\"Error:\",error)\n",
    "        self.error = error\n",
    "        \n",
    "        return weight\n",
    "    \n",
    "    def fit(self, x, y, verbal = False):\n",
    "        \n",
    "        self.x = x_train\n",
    "        self.y = y_train\n",
    "        step = 0\n",
    "        \n",
    "        if self.add is True:\n",
    "            x_with_intercept = np.c_[x_train, np.ones((self.x.shape[0],1))]\n",
    "            self.weight = np.zeros(x_with_intercept.shape[1])  # initial weight\n",
    "            errorlist = [100000]\n",
    "            \n",
    "            while step < self.iter:\n",
    "#                 print(\"Iteration:\", step+1, end=\"; \")\n",
    "                step += 1\n",
    "                self.weight = self.newton_raphson(x_with_intercept, self.weight, y_train, self.reg_vec)\n",
    "                errorlist.append(self.error)\n",
    "                if errorlist[-2] - self.error >= self.tol:\n",
    "                    continue\n",
    "                else:\n",
    "                    return self.error\n",
    "\n",
    "        else:\n",
    "            self.weight = np.zeros(x_train.shape[1])\n",
    "            errorlist = [100000]\n",
    "            \n",
    "            while step < self.iter:\n",
    "#                 print(\"Iteration:\", step+1, end=\"; \")\n",
    "                step += 1\n",
    "                self.weight = self.newton_raphson(x_train, self.weight, y_train, self.reg_vec)\n",
    "                errorlist.append(self.error)\n",
    "                if errorlist[-2] - self.error >= self.tol:\n",
    "                    continue\n",
    "                else:\n",
    "                    return self.error\n",
    "\n",
    "    def predict(self, x):\n",
    "        \n",
    "        self.x = x_test\n",
    "        \n",
    "        if self.add is True:\n",
    "            x_test_with_intercept = np.c_[x_test, np.ones((self.x.shape[0],1))]\n",
    "            prob = self.sigmoid(x_test_with_intercept @ self.weight)\n",
    "        else:\n",
    "            prob = self.sigmoid(x_test @ self.weight)\n",
    "        \n",
    "        pred = []\n",
    "        \n",
    "        for p in prob:\n",
    "            if p >= 0.5:\n",
    "                pred.append(1)\n",
    "            else:\n",
    "                pred.append(0)\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8785.72750191898, 8791.664403651212, 8798.221864710666, 8803.3155894323, 8807.732094045889, 8811.726276331345, 8815.419285342643, 8818.881704208668, 8822.159623850943, 8825.285380715197]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 先 fix a1\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, test_size = 0.1, random_state = 42)\n",
    "grid = np.linspace(0.01, 2, 10)\n",
    "lambda_vec_list = []\n",
    "errorlist = []\n",
    "for i in range(10):\n",
    "    lambda_vec_list.append(np.eye(len(x_train[0]))*grid[i])\n",
    "    for j in range(6):\n",
    "        lambda_vec_list[i][j][j] = 0.01  # 現在lambda_vec_list有10個matrix了\n",
    "    logic1 = Mylogistic_l2(reg_vec = lambda_vec_list[i], max_iter = 1000, tol = 1e-5, add_intercept = False)\n",
    "    logic1.fit(x_train, y_train)\n",
    "    errorlist.append(logic1.fit(x_train, y_train))\n",
    "print(errorlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8785.72750191898"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(errorlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "發現在固定a1=0.01時，a2=0.01有最小的error，所以接著我們固定a2=0.01找a1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8785.72750191898, 8787.107634784565, 8788.083117915807, 8788.88130213332, 8789.584652408339, 8790.231068056006, 8790.840559825121, 8791.424725982662, 8791.99075896714, 8792.543353830752]\n"
     ]
    }
   ],
   "source": [
    "lambda_vec_list1 = []\n",
    "errorlist1 = []\n",
    "for i in range(10):\n",
    "    lambda_vec_list1.append(np.eye(len(x_train[0]))*0.01)\n",
    "    for j in range(6):\n",
    "        lambda_vec_list1[i][j][j] = grid[i]\n",
    "    logic1 = Mylogistic_l2(reg_vec = lambda_vec_list1[i], max_iter = 1000, tol = 1e-5, add_intercept = False)\n",
    "    logic1.fit(x_train, y_train)\n",
    "    errorlist1.append(logic1.fit(x_train, y_train))\n",
    "print(errorlist1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8785.72750191898"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(errorlist1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後發現在固定a2=0.01時，a1=0.01有最小的error，因此最佳解為a1 = 0.01, a2 = 0.01。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1; Error: 18815.48021629972\n",
      "Iteration: 2; Error: 10695.772627538212\n",
      "Iteration: 3; Error: 9374.297819617219\n",
      "Iteration: 4; Error: 8882.256378451568\n",
      "Iteration: 5; Error: 8789.91308674253\n",
      "Iteration: 6; Error: 8780.912717179377\n",
      "Iteration: 7; Error: 8785.72750191898\n",
      "Weight:\n",
      " [ 2.57199845e-01  3.53383608e-01  2.35830465e+00  1.24427994e+00\n",
      "  3.37075426e-01  7.98424090e-02 -8.63797463e-01 -2.84183216e-01\n",
      " -1.34300165e+00 -1.43404153e+00 -3.57474148e-01  4.64510855e-01\n",
      " -1.14296609e+00 -3.07092465e-01 -7.10910882e-01 -1.09552479e+00\n",
      " -5.61492927e-01 -2.32858745e+00 -1.48939970e+00  8.46866826e-01\n",
      "  9.27587225e-01  1.67348512e+00 -1.29949592e-01  2.04399484e-01\n",
      "  5.74721176e-01  9.04255453e-02 -3.03654880e+00  1.38469367e+00\n",
      "  1.46807340e+00  1.15135620e+00  1.51460185e+00  7.80833561e-01\n",
      "  7.95515209e-01  4.35656181e-01  3.56452016e-01  1.98422817e+00\n",
      "  1.93109897e+00  1.27200541e+00  1.18316595e+00 -7.84470097e-01\n",
      " -2.89595326e-01 -6.65923385e-01 -1.06937824e+00  1.73845221e-01\n",
      " -8.18524630e-01 -7.58642430e+00 -7.41259450e-01  5.62115502e-03\n",
      "  1.11957521e+00  5.08920281e-01 -4.89381468e-01 -1.63114202e+00\n",
      "  6.39626233e-01 -1.45934176e+00  2.90396171e-02 -2.40333395e-01\n",
      "  5.56988454e-01  8.95202095e-01  5.92494960e-01 -6.26023669e-01\n",
      " -3.77764268e-01  3.81109681e-01 -6.83319318e-01  2.10174930e-01\n",
      "  1.48861618e-01 -2.93759826e-01  3.10568546e-01  7.17615055e-01\n",
      "  1.01270895e+00  1.61783278e-01  5.76364440e-01 -3.83910688e-01\n",
      " -1.95331471e-01 -3.05394945e-01 -3.63216669e+00 -1.22107720e+00\n",
      "  5.57551199e-01  1.64756505e-01  4.14940608e-01 -1.04912808e-01\n",
      "  1.73991453e-03 -9.09986265e-01  7.47313107e-02 -4.44023753e-01\n",
      " -1.68175218e-01  4.48426910e-01 -9.34304376e-01  1.76960902e+00\n",
      "  6.27247792e-01 -5.78934605e-02  1.41283685e-01  3.10767937e-01\n",
      " -3.78067865e-01 -2.15557852e-01 -4.24576739e+00 -1.20513310e+00\n",
      "  1.64780979e+00  1.04193377e+00 -1.29779245e+00 -1.69754309e+00\n",
      " -1.29035347e+00 -1.01690860e+00]\n",
      "Accuracy 0.8471447543160691\n"
     ]
    }
   ],
   "source": [
    "lambda_vec = np.eye(len(x_train[0]))\n",
    "lambda_vec /= 100\n",
    "\n",
    "logic1 = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = False)\n",
    "logic1.fit(x_train, y_train)\n",
    "ypred = logic1.predict(x_test)\n",
    "acc = list(ypred != y_test).count(False) / len(ypred)\n",
    "print(\"Weight:\\n\", logic1.weight)\n",
    "print(\"Accuracy\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.25608624  0.35219029  2.33809127  0.74363615  0.33522202  0.07791258\n",
      " -0.26998353  0.10390025 -0.85701789 -0.99947118  0.0254779   1.04196975\n",
      " -0.52996438  0.22042576 -0.13618572 -0.52460045  0.01520008 -0.89622808\n",
      " -0.05889663  0.0430822   0.12327231  0.86291289 -0.90882338 -0.57943128\n",
      " -0.23087636 -0.70925436 -1.45039893  0.57659313  0.65458281  0.34556662\n",
      "  0.70452038 -0.02450862 -0.03870747 -0.203413   -0.09493532  0.2710289\n",
      "  0.4507262   0.03810166  0.14014188 -0.43518264 -0.14124367 -0.12818494\n",
      "  0.05346645 -0.07549983 -0.08266621 -0.83611013  0.17672052 -0.04936712\n",
      "  0.52615183  0.37349241 -0.47560693 -1.14633505  0.47844794 -0.91422092\n",
      " -0.04479314 -0.27305122  0.40689035  0.67381572  0.46837583 -0.56499446\n",
      " -0.26054235  0.19240912 -0.08055113  0.10873951  0.02822111 -0.34259304\n",
      "  0.19616515  0.44737289  0.80984821  0.06873927  0.42778828 -0.25110631\n",
      " -0.27795166 -0.27725819 -0.57460585 -0.62058328  0.52118686  0.07436772\n",
      "  0.24391328 -0.15560931 -0.05859638 -0.8079774   0.0103036  -0.31501131\n",
      " -0.14767672  0.35197124 -0.78613387  1.02121075  0.54975029 -0.12227029\n",
      "  0.07328138  0.24407676 -0.44398603 -0.28050275 -0.97547406 -0.69258924\n",
      "  1.61300769  1.34561727 -0.76950412 -1.18764444 -0.76948954 -0.49452233]\n",
      "0.8470783532536521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdfg\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(x_train, y_train)\n",
    "y_result = clf.predict(x_test)\n",
    "\n",
    "print(clf.coef_[0])\n",
    "print(accuracy_score(y_test, y_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "係數除少數幾項普遍上差異不大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00111361,  0.00119332,  0.02021338,  0.50064378,  0.0018534 ,\n",
       "        0.00192983, -0.59381393, -0.38808347, -0.48598376, -0.43457035,\n",
       "       -0.38295205, -0.5774589 , -0.61300172, -0.52751823, -0.57472516,\n",
       "       -0.57092434, -0.57669301, -1.43235938, -1.43050308,  0.80378462,\n",
       "        0.80431492,  0.81057223,  0.77887379,  0.78383076,  0.80559753,\n",
       "        0.7996799 , -1.58614987,  0.80810055,  0.81349059,  0.80578958,\n",
       "        0.81008146,  0.80534218,  0.83422267,  0.63906918,  0.45138734,\n",
       "        1.71319927,  1.48037277,  1.23390375,  1.04302407, -0.34928746,\n",
       "       -0.14835166, -0.53773845, -1.1228447 ,  0.24934505, -0.73585842,\n",
       "       -6.75031417, -0.91797997,  0.05498827,  0.59342338,  0.13542787,\n",
       "       -0.01377453, -0.48480697,  0.1611783 , -0.54512084,  0.07383275,\n",
       "        0.03271782,  0.1500981 ,  0.22138638,  0.12411913, -0.06102921,\n",
       "       -0.11722192,  0.18870056, -0.60276819,  0.10143542,  0.12064051,\n",
       "        0.04883321,  0.11440339,  0.27024217,  0.20286074,  0.09304401,\n",
       "        0.14857616, -0.13280438,  0.08262019, -0.02813675, -3.05756085,\n",
       "       -0.60049391,  0.03636434,  0.09038878,  0.17102733,  0.05069651,\n",
       "        0.06033629, -0.10200887,  0.06442771, -0.12901244, -0.0204985 ,\n",
       "        0.09645567, -0.1481705 ,  0.74839827,  0.0774975 ,  0.06437683,\n",
       "        0.0680023 ,  0.06669118,  0.06591816,  0.0649449 , -3.27029333,\n",
       "       -0.51254386,  0.03480209, -0.3036835 , -0.52828833, -0.50989865,\n",
       "       -0.52086393, -0.52238627])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "logic1.weight - clf.coef_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相減發現自己預測與套件的 Accuracy 差距相當小(大約就跟tol差不多)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.64010624169542e-05"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc - accuracy_score(y_test, y_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
